The term Computational Social Science (CSS, to abbreviate the mouthful) has been gaining currency lately, most recently in an article by <a href="https://www.nae.edu/Publications/Bridge/106112/106118.aspx" target="_blank">Duncan Watts</a> of Microsoft Research, and a blog post by <a href="http://seanjtaylor.com/post/77189787786/on-computational-social-science" target="_blank">Sean Taylor</a> of Facebook and NYU. Both focus on CSS as data science: using 'big data' and machine learning to make new discoveries about society. 

My own <a href="http://css.gmu.edu/" target="_blank">Department of Computational Social Science</a> has a slightly different focus, which neither essay really addresses: CSS as the intersection of social science and complex systems, often applied through agent-based models and social simulations. Data is exciting (and <a href="http://davidmasad.com/Research.html" target="_blank">much of my own research</a> is data-oriented), but I think it's important not to think of CSS as <emph>only</emph> a subset of data science. Many interesting social phenomena take place at different levels. Individuals decide whether or not to go join a protest, for example, and at some point the aggregate of their decisions (along with many other factors) may tip over into a revolution -- which in turn will have profound results 
on the individuals themselves. Data can help us figure out who decides to go protest (for better <a href="http://thelede.blogs.nytimes.com/2014/01/22/ominous-text-message-sent-to-protesters-in-kiev-sends-chills-around-the-internet/?_php=true&_type=blogs&_r=0" target="_blank">or for worse</a>), but may not be enough on its own to understand why the revolution happens when it does, or to predict in advance whether it will happen or not. More generally, individual decisionmaking may take forms that are not necessarily easily amenable to many data science techniques.  

Here's an example, from some recent research I've been working on. Suppose we have some data on individuals or households in a city. We know each individual's 'type' (ethnicity, or political orientation, or preference for red or green chile), the types of their immediate neighbors, and whether or not they decided to move at the end of some time step. The data looks like this:
<table>
<tr><td>Step</td><td>Agent_ID</td><td>Agent_Type</td><td>Neighbor_0</td><td>Neighbor_1</td><td>Neighbor_2</td><td>...</td><td>Neighbor_7</td><td>Happy</td></tr>
<tr><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>...</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>...</td><td>1</td><td>1</td></tr>
<tr><td>0</td><td>2</td><td>1</td><td>0</td><td>1</td><td>1</td><td>...</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>3</td><td>2</td><td>1</td><td>0</td><td>1</td><td>...</td><td>2</td><td>1</td></tr>
<tr><td>0</td><td>4</td><td>2</td><td>0</td><td>1</td><td>2</td><td>...</td><td>1</td><td>1</td></tr>
<tr><td></td></tr>
</table>

Now, it's easy enough to fit a statistical model to this data, to try and predict which agents will stay and which will move. Since we're trying to predict a binary outcome, let's start with a logistic regression. Using Python and Scikit-Learn:
[python]
features = log.columns[2:11]
logit = LogisticRegression()
scores = cross_validation.cross_val_score(logit, 
              log[features], log["Happy"], cv=5)
[/python]
The scores for prediction accuracy I got when I ran this were
[python]
[ 0.99541084  0.99562842  0.99628415  0.99715847  0.99781421]
[/python]

These scores are high -- remarkably high, and even unbelievably high if we were dealing with real data. You may have realized by this point that this isn't real data: it's the output of an implementation of the <a href="http://en.wikipedia.org/wiki/Thomas_Schelling#Models_of_segregation" target=_blank>Schelling segregation model</a> <a href="#footnote1">[1]</a>, a classic early example of agent-based modeling. 

In the model, agents are placed on a grid, and have only a mild preference for proximity to other agents of the same type as themselves; in this case, they are happy if they have at least 3 agents of the same type in the <a href="http://en.wikipedia.org/wiki/Moore_neighborhood" target="_blank">8 cells surrounding them</a>, and unhappy agents move at random to an empty cell. The model continues to run until a set number of steps have elapsed, or until all agents are happy where they are. 

Examining the results of the logistic regression doesn't directly tell us any of this. For example, the largest-magnitude coefficient is on the agent type, indicating that Type 2 agents are more likely to be unhappy -- which is an emergent property of the system when Type 2 is the minority, but is not part of the actual decision mechanic. The regression may be able to predict agents' decisions extremely accurately, but it doesn't intuitively yield the agents' actual decision process. More importantly, perhaps, the logistic regression alone can't tell us anything about the original model's main result: the emergence of segregation. 

What makes the model interesting is that even the agents' mild preference (remember, they would be happy living in a perfectly integrated neighborhood) results in a highly segregated equilibrium. Here's an example run converging to a fully-segregated equilibrium in just 26 steps.
[caption id="attachment_92" align="alignleft" width="246"]<a href="http://davidmasad.com/blog/wp-content/uploads/2014/02/SchellingStart.png"><img src="http://davidmasad.com/blog/wp-content/uploads/2014/02/SchellingStart.png" alt="Schelling model: start" width="246" height="249" class="size-full wp-image-92" /></a> Schelling model: start[/caption][caption id="attachment_93" align="alignright" width="246"]<a href="http://davidmasad.com/blog/wp-content/uploads/2014/02/SchellingEnd.png"><img src="http://davidmasad.com/blog/wp-content/uploads/2014/02/SchellingEnd.png" alt="Schelling model: equilibrium" width="246" height="249" class="size-full wp-image-93" /></a> Schelling model: equilibrium[/caption]
[caption id="attachment_101" align="aligncenter" width="384"]<a href="http://davidmasad.com/blog/wp-content/uploads/2014/02/SchellingMoving.png"><img src="http://davidmasad.com/blog/wp-content/uploads/2014/02/SchellingMoving.png" alt="Number of agents moving at each step" width="384" height="268" class="size-full wp-image-101" /></a> Number of agents moving at each step[/caption]

Now, if we have at least a general idea of the structure of the model (grid, agents, movement, etc.) we can re-implement it and give the agents the fitted logistic function as their decision rule, in hopes that it will replicate the macro-level results. 
[caption id="attachment_108" align="aligncenter" width="246"]<a href="http://davidmasad.com/blog/wp-content/uploads/2014/02/LogitSchellingEnd.png"><img src="http://davidmasad.com/blog/wp-content/uploads/2014/02/LogitSchellingEnd.png" alt="Model with logit decision rule, at equilibrium" width="246" height="249" class="size-full wp-image-108" /></a> Model with logit decision rule, at equilibrium[/caption]
[caption id="attachment_109" align="aligncenter" width="300"]<a href="http://davidmasad.com/blog/wp-content/uploads/2014/02/LogitSchellingMoving.png"><img src="http://davidmasad.com/blog/wp-content/uploads/2014/02/LogitSchellingMoving-300x214.png" alt="Number of agents moving at each step" width="300" height="214" class="size-medium wp-image-109" /></a> Number of agents moving at each step[/caption]

There's some segregation -- not as dramatic as we saw above, but not implausible for the Schelling model either. The dynamics that the model generates are fairly close, though I found that this varied widely between runs: sometimes the dynamics were similar, and other times they diverged dramatically. The logit is also dependent on the specific parameters the data was generated under. If the ratio if Type 1 and 2 agents were to change, running the model with the fitted decision rule will probably produce worse results -- making it more difficult to use the model to generate hypotheticals and counterfactuals.

I also ran the same analysis using random forests, which are known to be both powerful predictors and very difficult to interpret. They produced similar results, though I haven't tried to find out how robust they are to changing the model parameters.

Of course, if we knew the decision rule in advance, we could reshape the data in order to capture it, by counting the similar neighbors for each row and using that as the independent variable. For any real data, we are unlikely to have such a simple decision rule -- instead, we would have a qualitative theory we could attempt to test. But <a href="http://www.wired.com/science/discoveries/magazine/16-07/pb_theory" target="_blank">why worry about theory</a> when the theory-less model has an 0.99 fit?

Just as a data science approach may be insufficient on its own for finding the qualitative and emergent characteristics of a system, agent-based models may benefit from more engagement with data. One common criticism of ABMs is that they lack rigorous foundations. While I think that this is often unfair (particularly when the foundations are rigorous <emph>qualitative</emph> theory), it is the case that ABMs are often compared with real data only once they are built, either for validation or calibration. As far as I know, using machine learning to fit agent behavior (as I do here) is still uncommon.

Ultimately, I think computational social science will need to combine both approaches. Going forward, I'm hoping to extend the type of work I've shown here, using data science techniques to understand agent-level behavior and combining it with qualitative theory to situate that behavior within a larger interactive system. 

As always, code is available <a href="https://github.com/dmasad/Schelling_ML" target="_blank">on GitHub</a>.

<a id="footnote1">[1]</a>: Despite a folk belief to the contrary among some complex systems folks, the model doesn't actually explain residential racial segregation as it actually happened in the United States. <a href="http://en.wikipedia.org/wiki/Redlining" target="_blank">Redlining</a> was a top-down process if there ever was one, and even the 'bottom-up' processes that created segregation were often <a href="http://www.theatlantic.com/national/archive/2013/02/terrorism-is-politics-by-other-means/273469/" target="_blank">more violent</a> than Schelling's model describes. But I digress.